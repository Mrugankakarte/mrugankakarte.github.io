<!DOCTYPE html>
<html class="no-js" lang="en-us" scroll-behavior="smooth"><head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="description" content="Machine Learning">
    <meta name="author" content="Mrugank Akarte">

    <!-- Mobile Specific Meta -->
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.55.4" />

    <title>Reinforcement Learning | Blogs</title>


    <!-- Favicon -->
    <link rel="shortcut icon" type="image/x-icon" href="https://mrugankakarte.github.io/images/favicon.ico"/>

    <!-- CSS -->
    <!-- Fontawesome Icon font -->
    <link rel="stylesheet" href="https://mrugankakarte.github.io/plugins/themefisher-font/style.css">
    <!-- bootstrap.min css -->
    <link rel="stylesheet" href="https://mrugankakarte.github.io/plugins/bootstrap/dist/css/bootstrap.min.css">
    <!-- Animate.css -->
    <link rel="stylesheet" href="https://mrugankakarte.github.io/plugins/animate-css/animate.css">
    <!-- Magnific popup css -->
    <link rel="stylesheet" href="https://mrugankakarte.github.io/plugins/magnific-popup/dist/magnific-popup.css">
    <!-- Slick Carousel -->
    <link rel="stylesheet" href="https://mrugankakarte.github.io/plugins/slick-carousel/slick/slick.css">
    <link rel="stylesheet" href="https://mrugankakarte.github.io/plugins/slick-carousel/slick/slick-theme.css">
    <!-- Main Stylesheet -->
    
    <link rel="stylesheet" href="https://mrugankakarte.github.io/css/style.min.css" integrity="" media="screen">
    <!-- Custom CSS -->
    
    <link rel="stylesheet" href="https://mrugankakarte.github.io/css/custom.css">
    

</head>
<body id="body" data-spy="scroll" data-target=".navbar" data-offset="52">
        <div id="content">

<!-- Fixed Navigation -->
<nav id="navigation" class="navbar navbar-expand-lg navigation sticky-top">
        <div class="container">

                <!-- logo -->
                <a class="navbar-brand logo" href="https://mrugankakarte.github.io">
                        <img src="https://mrugankakarte.github.io/images/logo.png" alt="Logo" />
                        <span class="pl-2 font-weight-bold">Mrugank Milind Akarte</span>
                </a>
                <!-- /logo -->

                <!-- responsive nav button -->
                <button class="navbar-toggler navbar-dark" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
                        <span class="navbar-toggler-icon"></span>
                </button>
                <!-- /responsive nav button -->

                <!-- main nav -->
                
                <div class="collapse navbar-collapse" id="navbarSupportedContent">
                        <ul class="navbar-nav ml-auto navigation-menu">
                                <li class="nav-item"><a class="nav-link" data-scroll href="https://mrugankakarte.github.io#body">Home</a></li>
                                
                                <li class="nav-item"><a class="nav-link" data-scroll href="https://mrugankakarte.github.io#about">About Me</a></li>
                                
                                <li class="nav-item"><a class="nav-link" data-scroll href="https://mrugankakarte.github.io#blog">Blog</a></li>
                                
                                <li class="nav-item"><a class="nav-link" data-scroll href="https://mrugankakarte.github.io#contact-us">Contact</a></li>
                                
                        </ul>
                </div>
                
                <!-- /main nav -->
        </div>

</nav>
<!-- End Fixed Navigation -->


<section class="section">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 offset-lg-2 text-center">
                <h1>Reinforcement Learning</h1>
                <ul class="list-inline mb-50">
                    <li class="list-inline-item"><a href="/author/mrugank-akarte">Mrugank Akarte</a></li>
                    <li class="list-inline-item">Monday, May 6, 2019</li>
                </ul>
                <img class="img-fluid mb-50" src="https://mrugankakarte.github.io/images/blog/reinforcement-learning.jpg" alt="blog-image">
            </div>
            <div class="col-lg-8 offset-lg-2">
                <div class="post-single-content">
                    

<h1 id="introduction">Introduction</h1>

<p>Reinforcement learning is a type of machine learning problem which is solved using the past experiences and interactions of the agent with the world. In other words, Reinforcement learning is mappings of stiuations with the available actions to maximize a numerical reward signal. Usually rewards are positive if the action taken is desirable and negative if the action is undesirable. The agent is never told which action to take or which action is optimal for a given situation, but instead it must discover on its own which actions to take that would yeild maximum reward. In many cases the action taken for a given situation may affect not only immediate reward but also the next situation and may have consequences on future rewards. These characteristics of trial and error search and delayed rewards and distinguishing features of reinforcement learning.</p>

<p>Reinforcment learning is different from supervised and unsupervised learning. Supervised learning is learning for a training set of known and labelled examples. Each example contains a set of features with its appropriate label. Reinforcement learning is an interactive problem in which it is often imposible to obtain the examples of desired behaviour that are both correct and representative of all situation for which the agent has to act. Unsupervised learning is about finding hidden structure in an unlabelled dataset. Reinforcement learning is about maximizing the reward by taking actions in an unseen situation. Although finding hidden structure in data will be useful for learning but it does not address its the objective. Hence, Reinforcment is considered different from supervised and unsupervised machine learning.</p>

<p>The problem of reinforcment learning is formalized as a fully observed or partial Markov Decision Process (MDP). We will discuss MDP subsequently, first lets discuss the basic terminologies used in reinforcment learning and one the most important challenges faced, trade-off between exploration and exploitation. To obtain a positive reward, the agent has to take right action for a given situation. Since the agent is never told what the optimal action is, the agent has to take some action experience the consequences. It has to try all the actions available and then select the action which gives maximum reward. In this process the agent has to <em>exploit</em> what he already knows from the previous actions taken and <em>explore</em> all the possible options to make a better action selection in the future. The dilemma here is that neither exploration nor exploitation can be pursued exclusively without failing at task. The agent must try a variety of actions and progressively favor those which appear to be best.</p>

<p><img src="/blog/images/rl-mdp.PNG" alt="mdp" title="Markov Decision Process" />(<em>Source: Richard Sutton and Andrew Barto, Reinforcement learning Second Edition 2018</em>)</p>

<h1 id="reinforcement-learning-system">Reinforcement learning system</h1>

<p>Reinforcement learning system consists of <em>a policy</em>, <em>reward signal</em>, <em>value function</em>, and optinally <em>a model</em> of environment.</p>

<ul>
<li><em>Policy</em> defines what action to take at any given situation (hereafter referred as <em>state</em>). It is basically a mapping of actions to states of environment. It can be as simple as any function or a lookup table.</li>
<li><em>Reward signal</em> defines the goal of a reinforcement learning problem. After taking an action on a given state, the agent receives a reward which can be positive or negative. This reward is then used to adjust the policy in such a way that future actions are better. Positive rewards define what events are good for agent whereas negative rewards define the bad events. The sole objective of the agent is to maximize the reward over long term.</li>
<li>Reward indicates what is good in immediate sense, <em>Value function</em> defines what is good in long run. It gives an estimate of total amount of reward that an agent can accumulate over future starting from that state.</li>
<li><em>Model</em> is something that can mimic an environment. For a given state and action, a model can predict the next state and next reward. Model can be used for planning and considering possible states before experiencing them. Reinforcement learning problems which use models are known as <em>model-based</em> methods. <em>Model-free</em> methods are purely based on trial-error learners.</li>
</ul>

<h1 id="markov-decision-process">Markov Decision Process</h1>

<p>Markov Decision Process (MDP) provide a framework to model decision making process where outcomes are partly random and partly under the control of decision maker. The learner or decision maker is called an <em>agent</em>. The agent interacts with the <em>environment</em> which comprises of everything except the agent.</p>

<p>The process flow in a MDP is as follows:<br />
1. We get the current state from the environment<br />
2. Agent takes action from all possible actions for the given state<br />
3. Environment reacts to the action taken by agent and present the reward and next state<br />
4. We modify the agents policy based on the rewards received<br />
5. Agent again acts for the new state using the modified policy</p>

<p>This process continues untill the task is acomplished.</p>

<h1 id="policy-and-value-functions">Policy and Value Functions</h1>

<p><em>Value functions</em> are functions that estimate &ldquo;how good&rdquo; it is for a agent to be in a given state. This is defined in terms of future rewards that can be expected. Value functions are defined with respect to particular ways of acting called <em>policies</em>.</p>

<p>A <em>policy function</em> can be defined as mapping between the state and probability of selecting each possible action. Mathematically value function is defined as follows:</p>

<p><img src="/blog/images/rl-valuefun.PNG" alt="state value function" title="State Value Function" />(<em>Source: Richard Sutton and Andrew Barto, Reinforcement learning Second Edition 2018</em>)</p>

<p>where, <strong>E<sub>&#00960;</sub>[.]</strong> denotes expected value of random variable given that agent follows the policy <em>&#00960;</em> and <em>t</em> is any time-step. This is also known as <em>state-value function for policy &#00960;</em>.</p>

<p>Similarly <em>action-value function</em> is defined as value of taking action <em>a</em>, given state <em>s</em> under policy &#00960;.
<img src="/blog/images/rl-actionvaluefunction.PNG" alt="action value function" title="Action value Function" />(<em>Source: Richard Sutton and Andrew Barto, Reinforcement learning Second Edition 2018</em>)</p>

<h3 id="value-based-reinforcement-learning">Value based reinforcement learning</h3>

<p>In value based learning, the objective is to optimize the value function. The agent will use this value function to select the action for a given state. The agent takes the action with the biggest value.</p>

<h3 id="policy-based-reinforcement-learning">Policy based reinforcement learning</h3>

<p>In policy based reinforcement learning, the objective is to optimize the policy function &#00960;(s) The policy determines the probability for each possible action given a state and an action from this probability distribution is selected.</p>

<p>In next article we will discuss about the value based methods called <em>Q-learning</em>, <em>Deep Q-Learning</em> and its varients.</p>

<p><em>PS: Most of the details are from Barto and Sutton, Reinforcement Book, Second Edition 2018. This post is my understanding of the topics from the book. If you would like to go in more details please refer the book.</em></p>

                    
                        

<div class="social-share pt-4">
        <h4>Share:</h4>
        
        <a class="resp-sharing-button__link" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fmrugankakarte.github.io%2fblog%2freinforcement-learning%2f" target="_blank" rel="noopener" aria-label="">
            <div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18.77 7.46H14.5v-1.9c0-.9.6-1.1 1-1.1h3V.5h-4.33C10.24.5 9.5 3.44 9.5 5.32v2.15h-3v4h3v12h5v-12h3.85l.42-4z"/></svg>
            </div>
        </div>
    </a>

    
    <a class="resp-sharing-button__link" href="https://twitter.com/intent/tweet/?text=Reinforcement%20Learning&amp;url=https%3a%2f%2fmrugankakarte.github.io%2fblog%2freinforcement-learning%2f" target="_blank" rel="noopener" aria-label="">
        <div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M23.44 4.83c-.8.37-1.5.38-2.22.02.93-.56.98-.96 1.32-2.02-.88.52-1.86.9-2.9 1.1-.82-.88-2-1.43-3.3-1.43-2.5 0-4.55 2.04-4.55 4.54 0 .36.03.7.1 1.04-3.77-.2-7.12-2-9.36-4.75-.4.67-.6 1.45-.6 2.3 0 1.56.8 2.95 2 3.77-.74-.03-1.44-.23-2.05-.57v.06c0 2.2 1.56 4.03 3.64 4.44-.67.2-1.37.2-2.06.08.58 1.8 2.26 3.12 4.25 3.16C5.78 18.1 3.37 18.74 1 18.46c2 1.3 4.4 2.04 6.97 2.04 8.35 0 12.92-6.92 12.92-12.93 0-.2 0-.4-.02-.6.9-.63 1.96-1.22 2.56-2.14z"/></svg>
        </div>
    </div>
</a>


<a class="resp-sharing-button__link" href="https://plus.google.com/share?url=https%3a%2f%2fmrugankakarte.github.io%2fblog%2freinforcement-learning%2f" target="_blank" rel="noopener" aria-label="">
    <div class="resp-sharing-button resp-sharing-button--google resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M11.37 12.93c-.73-.52-1.4-1.27-1.4-1.5 0-.43.03-.63.98-1.37 1.23-.97 1.9-2.23 1.9-3.57 0-1.22-.36-2.3-1-3.05h.5c.1 0 .2-.04.28-.1l1.36-.98c.16-.12.23-.34.17-.54-.07-.2-.25-.33-.46-.33H7.6c-.66 0-1.34.12-2 .35-2.23.76-3.78 2.66-3.78 4.6 0 2.76 2.13 4.85 5 4.9-.07.23-.1.45-.1.66 0 .43.1.83.33 1.22h-.08c-2.72 0-5.17 1.34-6.1 3.32-.25.52-.37 1.04-.37 1.56 0 .5.13.98.38 1.44.6 1.04 1.84 1.86 3.55 2.28.87.23 1.82.34 2.8.34.88 0 1.7-.1 2.5-.34 2.4-.7 3.97-2.48 3.97-4.54 0-1.97-.63-3.15-2.33-4.35zm-7.7 4.5c0-1.42 1.8-2.68 3.9-2.68h.05c.45 0 .9.07 1.3.2l.42.28c.96.66 1.6 1.1 1.77 1.8.05.16.07.33.07.5 0 1.8-1.33 2.7-3.96 2.7-1.98 0-3.54-1.23-3.54-2.8zM5.54 3.9c.33-.38.75-.58 1.23-.58h.05c1.35.05 2.64 1.55 2.88 3.35.14 1.02-.08 1.97-.6 2.55-.32.37-.74.56-1.23.56h-.03c-1.32-.04-2.63-1.6-2.87-3.4-.13-1 .08-1.92.58-2.5zM23.5 9.5h-3v-3h-2v3h-3v2h3v3h2v-3h3"/></svg>
    </div>
</div>
</a>


<a class="resp-sharing-button__link" href="mailto:?subject=Reinforcement%20Learning&amp;body=https%3a%2f%2fmrugankakarte.github.io%2fblog%2freinforcement-learning%2f" target="_self" rel="noopener" aria-label="">
    <div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M22 4H2C.9 4 0 4.9 0 6v12c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zM7.25 14.43l-3.5 2c-.08.05-.17.07-.25.07-.17 0-.34-.1-.43-.25-.14-.24-.06-.55.18-.68l3.5-2c.24-.14.55-.06.68.18.14.24.06.55-.18.68zm4.75.07c-.1 0-.2-.03-.27-.08l-8.5-5.5c-.23-.15-.3-.46-.15-.7.15-.22.46-.3.7-.14L12 13.4l8.23-5.32c.23-.15.54-.08.7.15.14.23.07.54-.16.7l-8.5 5.5c-.08.04-.17.07-.27.07zm8.93 1.75c-.1.16-.26.25-.43.25-.08 0-.17-.02-.25-.07l-3.5-2c-.24-.13-.32-.44-.18-.68s.44-.32.68-.18l3.5 2c.24.13.32.44.18.68z"/></svg>
    </div>
</div>
</a>


<a class="resp-sharing-button__link" href="https://reddit.com/submit/?url=https%3a%2f%2fmrugankakarte.github.io%2fblog%2freinforcement-learning%2f&amp;resubmit=true&amp;title=Reinforcement%20Learning" target="_blank" rel="noopener" aria-label="">
    <div class="resp-sharing-button resp-sharing-button--reddit resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M24 11.5c0-1.65-1.35-3-3-3-.96 0-1.86.48-2.42 1.24-1.64-1-3.75-1.64-6.07-1.72.08-1.1.4-3.05 1.52-3.7.72-.4 1.73-.24 3 .5C17.2 6.3 18.46 7.5 20 7.5c1.65 0 3-1.35 3-3s-1.35-3-3-3c-1.38 0-2.54.94-2.88 2.22-1.43-.72-2.64-.8-3.6-.25-1.64.94-1.95 3.47-2 4.55-2.33.08-4.45.7-6.1 1.72C4.86 8.98 3.96 8.5 3 8.5c-1.65 0-3 1.35-3 3 0 1.32.84 2.44 2.05 2.84-.03.22-.05.44-.05.66 0 3.86 4.5 7 10 7s10-3.14 10-7c0-.22-.02-.44-.05-.66 1.2-.4 2.05-1.54 2.05-2.84zM2.3 13.37C1.5 13.07 1 12.35 1 11.5c0-1.1.9-2 2-2 .64 0 1.22.32 1.6.82-1.1.85-1.92 1.9-2.3 3.05zm3.7.13c0-1.1.9-2 2-2s2 .9 2 2-.9 2-2 2-2-.9-2-2zm9.8 4.8c-1.08.63-2.42.96-3.8.96-1.4 0-2.74-.34-3.8-.95-.24-.13-.32-.44-.2-.68.15-.24.46-.32.7-.18 1.83 1.06 4.76 1.06 6.6 0 .23-.13.53-.05.67.2.14.23.06.54-.18.67zm.2-2.8c-1.1 0-2-.9-2-2s.9-2 2-2 2 .9 2 2-.9 2-2 2zm5.7-2.13c-.38-1.16-1.2-2.2-2.3-3.05.38-.5.97-.82 1.6-.82 1.1 0 2 .9 2 2 0 .84-.53 1.57-1.3 1.87z"/></svg>
    </div>
</div>
</a>


<a class="resp-sharing-button__link" href="whatsapp://send?text=Reinforcement%20Learning%20https%3a%2f%2fmrugankakarte.github.io%2fblog%2freinforcement-learning%2f" target="_blank" rel="noopener" aria-label="">
    <div class="resp-sharing-button resp-sharing-button--whatsapp resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.1 3.9C17.9 1.7 15 .5 12 .5 5.8.5.7 5.6.7 11.9c0 2 .5 3.9 1.5 5.6L.6 23.4l6-1.6c1.6.9 3.5 1.3 5.4 1.3 6.3 0 11.4-5.1 11.4-11.4-.1-2.8-1.2-5.7-3.3-7.8zM12 21.4c-1.7 0-3.3-.5-4.8-1.3l-.4-.2-3.5 1 1-3.4L4 17c-1-1.5-1.4-3.2-1.4-5.1 0-5.2 4.2-9.4 9.4-9.4 2.5 0 4.9 1 6.7 2.8 1.8 1.8 2.8 4.2 2.8 6.7-.1 5.2-4.3 9.4-9.5 9.4zm5.1-7.1c-.3-.1-1.7-.9-1.9-1-.3-.1-.5-.1-.7.1-.2.3-.8 1-.9 1.1-.2.2-.3.2-.6.1s-1.2-.5-2.3-1.4c-.9-.8-1.4-1.7-1.6-2-.2-.3 0-.5.1-.6s.3-.3.4-.5c.2-.1.3-.3.4-.5.1-.2 0-.4 0-.5C10 9 9.3 7.6 9 7c-.1-.4-.4-.3-.5-.3h-.6s-.4.1-.7.3c-.3.3-1 1-1 2.4s1 2.8 1.1 3c.1.2 2 3.1 4.9 4.3.7.3 1.2.5 1.6.6.7.2 1.3.2 1.8.1.6-.1 1.7-.7 1.9-1.3.2-.7.2-1.2.2-1.3-.1-.3-.3-.4-.6-.5z"/></svg>
    </div>
</div>
</a>


<a class="resp-sharing-button__link" href="https://telegram.me/share/url?text=Reinforcement%20Learning&amp;url=https%3a%2f%2fmrugankakarte.github.io%2fblog%2freinforcement-learning%2f" target="_blank" rel="noopener" aria-label="">
    <div class="resp-sharing-button resp-sharing-button--telegram resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M.707 8.475C.275 8.64 0 9.508 0 9.508s.284.867.718 1.03l5.09 1.897 1.986 6.38a1.102 1.102 0 0 0 1.75.527l2.96-2.41a.405.405 0 0 1 .494-.013l5.34 3.87a1.1 1.1 0 0 0 1.046.135 1.1 1.1 0 0 0 .682-.803l3.91-18.795A1.102 1.102 0 0 0 22.5.075L.706 8.475z"/></svg>
    </div>
</div>
</a>

</div>
                    
                    

                </div>
            </div>
        </div>
    </div>
</section>


        </div><!-- end Contact Area -->
<footer id="footer" class="bg-one">
	<div class="container">
		<div class="row wow fadeInUp" data-wow-duration="500ms">
			<div class="col-xl-12">

				<!-- Footer Social Links -->
				<div class="social-icon">
					<ul class="list-inline">
						
						<li class="list-inline-item"><a href="#"><i class="tf-ion-social-youtube"></i></a></li>
						
						<li class="list-inline-item"><a href="#"><i class="tf-ion-social-linkedin"></i></a></li>
						
						<li class="list-inline-item"><a href="#"><i class="tf-ion-social-instagram"></i></a></li>
						
						<li class="list-inline-item"><a href="#"><i class="tf-ion-social-github"></i></a></li>
						
					</ul>
				</div>

				<!-- copyright -->
				<div class="copyright text-center">
					<a href="https://mrugankakarte.github.io">
						<img src="https://mrugankakarte.github.io/images/logo.png" alt="Meghna" />
					</a>
					<br>
					<p>Design And Developed by <a href="http://www.themefisher.com">  Themefisher Team  </a>. Copyright &copy; <script>
							document.write(new Date().getFullYear())
						</script>. All Rights Reserved.</p>
				</div>
			</div>
		</div>
	</div>
</footer>
<!-- /footer -->

<!-- Essential Scripts -->

		<!-- Main jQuery -->
		<script type="text/javascript" src="https://mrugankakarte.github.io/plugins/jquery/dist/jquery.min.js"></script>
		<!-- Bootstrap 4.3 + Popper -->
		<script type="text/javascript" src="https://mrugankakarte.github.io/plugins/bootstrap/dist/js/bootstrap.bundle.min.js"></script>
		<!-- Slick Carousel -->
		<script type="text/javascript" src="https://mrugankakarte.github.io/plugins/slick-carousel/slick/slick.min.js"></script>
		<!-- Portfolio Filtering -->
		<script type="text/javascript" src="https://mrugankakarte.github.io/plugins/filterzr/jquery.filterizr.min.js"></script>
		<!-- Magnific popup -->
		<script type="text/javascript" src="https://mrugankakarte.github.io/plugins/magnific-popup/dist/jquery.magnific-popup.min.js"></script>
		<!-- Google Map API -->
		<script type="text/javascript"  src="https://mrugankakarte.github.io"></script>
		<!-- Number Counter Script -->
		<script type="text/javascript" src="https://mrugankakarte.github.io/plugins/count-to/jquery.countTo.js"></script>
		<!-- wow.min Script -->
		<script type="text/javascript" src="https://mrugankakarte.github.io/plugins/wow/dist/wow.min.js"></script>
		<!-- Scroll behavior polyfill -->
		
		<script src="https://mrugankakarte.github.io/js/scroll-behavior-polyfill.min.js"></script>
		<!-- Sweet Alert -->
		<script type="text/javascript" src="https://mrugankakarte.github.io/plugins/sweet-alert/sweetalert.min.js"></script>
		<!-- Custom js -->
		
		<script src="https://mrugankakarte.github.io/js/script.min.js"></script>
		<!-- google analitycs -->
		<script>
				(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
				(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
				m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
				})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
				ga('create', 'Your ID', 'auto');
				ga('send', 'pageview');
		</script>

    </body>
</html></body>
</html>
