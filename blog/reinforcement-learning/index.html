<!DOCTYPE html>
<html lang="en-us"
    dir="ltr"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no, maximum-scale=1">
    <title>
    
    Reinforcement Learning - Mrugank M Akarte
    
</title>
    
    
    
    
    
    
    
    
    <meta name="keywords" content="Mrugank, Mrugank Akarte">
    <meta name="description" content="Reinforcement Learning">
    <link rel="canonical" href="http://localhost:1313/blog/reinforcement-learning/" />
    <link rel="icon" href="/favicon.ico?v=1741233249" type="image/x-icon">
    
<link rel="stylesheet" href="/css/app.css">
    
<script src="/js/main.js"></script>


<script defer src="https://cdn.jsdelivr.net/npm/alpinejs@3.13.10/dist/cdn.min.js"></script>

    
    
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=%2a%2a%2a%2a%2a%2a" crossorigin="anonymous"></script>
    

    
    
    <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', '******');
    </script>
    

    
    
    <script type="text/javascript"
        src="https://platform-api.sharethis.com/js/sharethis.js#property=&product=sticky-share-buttons"
        async="async"></script>
    
</head><body>
    <div class="
        mx-auto max-w-[calc(120rem)]
        min-h-screen
        2xl:px-[calc(16rem)]
        xl:px-24
        md:px-8
        px-4
    ">

        <div x-data="{ openMenu: false }" class="relative">
    <nav class="flex flex-1 flex-col lg:flex-row items-center justify-between">
        <a href="/">
            <img src="/favicon.ico?v=1741233249" alt="site logo"
                class="w-16 h-16 my-5 p-1 bg-gray-100 rounded-full cursor-pointer hover:scale-110" />
        </a>
        <div class="hidden lg:block" :class="{'hidden': !openMenu}">
            






<ul
    class="flex flex-col lg:flex-row justify-end mt-2 sm:mt-5 mb-5 pb-2 font-light text-xl lg:text-2xl gap-5 lg:gap-1 text-center">
    








<li>
    <a    class="px-5 lg:px-10 py-3 font-light hover:border-b-2 hover:border-red-500"     href="/"  >Home</a>
    
</li>







<li>
    <a    class="px-5 lg:px-10 py-3 font-light hover:border-b-2 hover:border-red-500"     href="/tags/"  >Tags</a>
    
</li>







<li>
    <a    class="px-5 lg:px-10 py-3 font-light hover:border-b-2 hover:border-red-500"    >Contact</a>
    
</li>


</ul>




        </div>
    </nav>
    <div class="absolute top-8 right-5 flex items-center lg:hidden">
        
        <button @click="openMenu = !openMenu" type="button"
            class="relative inline-flex items-center justify-center rounded-md p-2 text-gray-400 hover:bg-gray-800 hover:text-gray-100 focus:outline-hidden focus:ring-2 focus:ring-inset focus:ring-white"
            aria-controls="mobile-menu" aria-expanded="openMenu">
            
            <svg x-show="!openMenu" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                stroke="currentColor" aria-hidden="true">
                <path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" />
            </svg>
            
            <svg x-show="openMenu" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                stroke="currentColor" aria-hidden="true">
                <path stroke-linecap="round" stroke-linejoin="round" d="M6 18L18 6M6 6l12 12" />
            </svg>
        </button>
    </div>
</div>

        <header class="flex flex-col w-full items-center justify-center text-white pt-8 pb-8">
    <div class="w-full">
        <div class="flex flex-1 flex-row justify-between">
            <h2 class="w-full text-center text-3xl sm:text-5xl font-crimson font-bold tracking-tight text-gray-300">
                <a href="http://localhost:1313/">Mrugank M Akarte</a>
            </h2>
        </div>
        <p
            class="w-full text-center pl-1 pb-4 sm:pt-3 sm:pb-0 font-crimson font-normal text-xl sm:text-2xl leading-8 text-gray-500">
            Personal Blog</p>
    </div>

    <div class="relative w-9/12 lg:w-1/2 h-12 my-5">
        <form action="/en/search" method="get">
            <input
                class="bg-gray-800 placeholder:italic placeholder:text-gray-600 w-full h-12 rounded-full mt-1 pl-5 pr-5 border border-gray-800 text-gray-100"
                placeholder='Input Keywords...' type="text" name="q" id="search-query" />

            <button
                class="absolute inset-y-2 right-1 w-28 h-10 font-light bg-gray-900 hover:bg-red-500 text-gray-500 hover:text-gray-100 rounded-full cursor-pointer"
                type="submit">Search</button>
        </form>
    </div>

    
    <div class="w-full flex flex-row justify-start text-gray-500 text-lg px-1 border-l-4 border-l-red-500">
        <ul class="flex flex-row gap-x-2">
            <li class="">
                <a href="/" class="hover:text-gray-100">Home</a>
            </li>
            
            <li>
                &gt;&nbsp;&nbsp;<a href="/blog/reinforcement-learning/" class="hover:text-gray-100">Reinforcement Learning</a>
            </li>
            
        </ul>
    </div>
    <div class="w-full h-2 border-b border-b-gray-600/50 border-dashed font-light text-gray-300">
    </div>
    

</header>

        <div class="
            flex flex-col overflow-hidden
            xl:px-0
            lg:flex-row lg:space-x-8
        ">
            <main class="w-full overflow-hidden">
                

<article class="single-article">
    
    <div class="group relative">
        <h1 class="text-3xl font-medium leading-10 text-gray-400 hover:text-gray-100">
            <a href="/blog/reinforcement-learning/">
                Reinforcement Learning
            </a>
        </h1>
        <time datetime="2025-03-16" class="flex items-center py-2 text-xl text-gray-600">
            2019-05-06 20:00
            &nbsp;&nbsp;|&nbsp;&nbsp;5 minute read
        </time>

        <div
            class="mt-1 lg:pb-10 px-2 text-2xl leading-10 font-thin text-gray-500 overflow-hidden break-words article-body">
            <h2 id="introduction">Introduction</h2>
<p>Reinforcement learning is a type of machine learning problem which is solved using the past experiences and interactions of the agent with the world. In other words, Reinforcement learning is mappings of situations with the available actions to maximize a numerical reward signal. Usually rewards are positive if the action taken is desirable and negative if the action is undesirable. The agent is never told which action to take or which action is optimal for a given situation, but instead it must discover on its own which actions to take that would yield maximum reward. In many cases the action taken for a given situation may affect not only immediate reward but also the next situation and may have consequences on future rewards. These characteristics of trial and error search and delayed rewards are distinguishing features of reinforcement learning.</p>
<p>Reinforcement learning is different from supervised and unsupervised learning. Supervised learning is learning for a training set of known and labelled examples. Each example contains a set of features with its appropriate label. Reinforcement learning is an interactive problem in which it is often impossible to obtain the examples of desired behaviour that are both correct and representative of all situation for which the agent must act. Unsupervised learning is about finding hidden structure in an unlabelled dataset. Reinforcement learning is about maximizing the reward by taking actions in an unseen situation. Although finding hidden structure in data will be useful for learning but it does not address its the objective. Hence, Reinforcement is considered different from supervised and unsupervised machine learning.</p>
<p>The problem of reinforcement learning is formalized as a fully observed or partial Markov Decision Process (MDP). We will discuss MDP subsequently, first letâ€™s discuss the basic terminologies used in reinforcement learning and one the most important challenges faced, trade-off between exploration and exploitation. To obtain a positive reward, the agent has to take right action for a given situation. Since the agent is never told what the optimal action is, the agent must take some action and experience the consequences. It must try all the actions available and then select the action which gives maximum reward. In this process the agent has to <em>exploit</em> what he already knows from the previous actions taken and <em>explore</em> all the possible options to make a better action selection in the future. The dilemma here is that neither exploration nor exploitation can be pursued exclusively without failing at task. The agent must try a variety of actions and progressively favour those which appear to be best.</p>
<p><img src="/blog/rl/rl-mdp.PNG" alt="mdp" title="Markov Decision Process">(<em>Source: Richard Sutton and Andrew Barto, Reinforcement learning Second Edition 2018</em>)</p>
<h2 id="reinforcement-learning-system">Reinforcement learning system</h2>
<p>Reinforcement learning system consists of <em>a policy</em>, <em>reward signal</em>, <em>value function</em>, and optionally <em>a model</em> of environment.</p>
<ul>
<li><em>Policy</em> defines what action to take at any given situation (hereafter referred as <em>state</em>). It is basically a mapping of actions to states of environment. It can be as simple as any function or a lookup table.</li>
<li><em>Reward signal</em> defines the goal of a reinforcement learning problem. After taking an action on a given state, the agent receives a reward which can be positive or negative. This reward is then used to adjust the policy in such a way that future actions are better. Positive rewards define what events are good for agent whereas negative rewards define the bad events. The sole objective of the agent is to maximize the reward over long term.</li>
<li>Reward indicates what is good in immediate sense, <em>Value function</em> defines what is good in long run. It gives an estimate of total amount of reward that an agent can accumulate over future starting from that state.</li>
<li><em>Model</em> is something that can mimic an environment. For a given state and action, a model can predict the next state and next reward. Model can be used for planning and considering possible states before experiencing them. Reinforcement learning problems which use models are known as <em>model-based</em> methods. <em>Model-free</em> methods are purely based on trial-error learners.</li>
</ul>
<h2 id="markov-decision-process">Markov Decision Process</h2>
<p>Markov Decision Process (MDP) provide a framework to model decision making process where outcomes are partly random and partly under the control of decision maker. The learner or decision maker is called an <em>agent</em>. The agent interacts with the <em>environment</em> which comprises of everything except the agent.</p>
<p>The process flow in a MDP is as follows:</p>
<ol>
<li>We get the current state from the environment</li>
<li>Agent takes action from all possible actions for the given state</li>
<li>Environment reacts to the action taken by agent and present the reward and next state</li>
<li>We modify the agents policy based on the rewards received</li>
<li>Agent again acts for the new state using the modified policy</li>
</ol>
<p>This process continues until the task is accomplished.</p>
<h2 id="policy-and-value-functions">Policy and Value Functions</h2>
<p><em>Value functions</em> are functions that estimate &ldquo;how good&rdquo; it is for a agent to be in a given state. This is defined in terms of future rewards that can be expected. Value functions are defined with respect to particular ways of acting called <em>policies</em>.</p>
<p>A <em>policy function</em> can be defined as mapping between the state and probability of selecting each possible action. Mathematically value function is defined as follows:</p>
<p><img src="/blog/rl/rl-valuefun.PNG" alt="state value function" title="State Value Function">(<em>Source: Richard Sutton and Andrew Barto, Reinforcement learning Second Edition 2018</em>)</p>
<p>where,  <em>EÏ€[.]</em> denotes expected value of random variable given that agent follows the policy <em>Ï€</em> and <em>t</em> is any time-step. This is also known as <em>state-value function for policy Ï€</em>.</p>
<p>Similarly <em>action-value function</em> is defined as value of taking action <em>a</em>, given state <em>s</em> under policy Ï€.
<img src="/blog/rl/rl-actionvaluefunction.PNG" alt="action value function" title="Action value Function">(<em>Source: Richard Sutton and Andrew Barto, Reinforcement learning Second Edition 2018</em>)</p>
<h3 id="value-based-reinforcement-learning">Value based reinforcement learning</h3>
<p>In value based learning, the objective is to optimize the value function. The agent will use this value function to select the action for a given state. The agent takes the action with the biggest value.</p>
<h3 id="policy-based-reinforcement-learning">Policy based reinforcement learning</h3>
<p>In policy based reinforcement learning, the objective is to optimize the policy function Ï€(s) The policy determines the probability for each possible action given a state and an action from this probability distribution is selected.</p>
<p>In next article we will discuss about the value based methods called <em>Q-learning</em>, <em>Deep Q-Learning</em> and its variants.</p>
<p><em>PS: Most of the details are from Barto and Sutton, Reinforcement Book, Second Edition 2018. This post is my understanding of the topics from the book. If you would like to go in more details please refer the book.</em></p>

        </div>
    </div>
    <div class="text-gray-500 text-lg">
        Page link:&nbsp;<a href="http://localhost:1313/blog/reinforcement-learning/"
            class="border-b border-b-gray-500 hover:text-gray-400">http://localhost:1313/blog/reinforcement-learning/</a>
    </div>
    
    
        <div class="my-10 py-5 border-t border-dashed border-t-white/10 text-xl">
  <div id="disqus_thread"></div>
  <script>
      

      

      (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://guangmean.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments.</a></noscript>
</div>
    
</article>


            </main>

            <aside id="sidebar" class="aside-container">

    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M21 8.25c0-2.485-2.099-4.5-4.688-4.5-1.935 0-3.597 1.126-4.312 2.733-.715-1.607-2.377-2.733-4.313-2.733C5.1 3.75 3 5.765 3 8.25c0 7.22 9 12 9 12s9-4.78 9-12Z" />
        </svg>
        About Me
    </div>

    <img src="/image/logo.webp?v=1741233249" class="w-80 self-center" alt="Logo" />

    <p class="leading-8 text-center text-lg font-light mt-3">
        
    </p>

    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M9 12h3.75M9 15h3.75M9 18h3.75m3 .75H18a2.25 2.25 0 0 0 2.25-2.25V6.108c0-1.135-.845-2.098-1.976-2.192a48.424 48.424 0 0 0-1.123-.08m-5.801 0c-.065.21-.1.433-.1.664 0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75 2.25 2.25 0 0 0-.1-.664m-5.8 0A2.251 2.251 0 0 1 13.5 2.25H15c1.012 0 1.867.668 2.15 1.586m-5.8 0c-.376.023-.75.05-1.124.08C9.095 4.01 8.25 4.973 8.25 6.108V8.25m0 0H4.875c-.621 0-1.125.504-1.125 1.125v11.25c0 .621.504 1.125 1.125 1.125h9.75c.621 0 1.125-.504 1.125-1.125V9.375c0-.621-.504-1.125-1.125-1.125H8.25ZM6.75 12h.008v.008H6.75V12Zm0 3h.008v.008H6.75V15Zm0 3h.008v.008H6.75V18Z" />
        </svg>
        Latest Post
    </div>

    <ul class="text-lg">
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/project-minerl/" class="py-5 hover:text-gray-300">Project MineRL</a>
        </li>
        
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/inventory-optimization-with-reinforcement-learning/" class="py-5 hover:text-gray-300">Inventory Optimization: MDP vs RL</a>
        </li>
        
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/deep-q-learning/" class="py-5 hover:text-gray-300">Deep Q-Learning</a>
        </li>
        
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/q-learning/" class="py-5 hover:text-gray-300">Q-Learning</a>
        </li>
        
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/reinforcement-learning/" class="py-5 hover:text-gray-300">Reinforcement Learning</a>
        </li>
        
        
    </ul>

    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M2.25 7.125C2.25 6.504 2.754 6 3.375 6h6c.621 0 1.125.504 1.125 1.125v3.75c0 .621-.504 1.125-1.125 1.125h-6a1.125 1.125 0 0 1-1.125-1.125v-3.75ZM14.25 8.625c0-.621.504-1.125 1.125-1.125h5.25c.621 0 1.125.504 1.125 1.125v8.25c0 .621-.504 1.125-1.125 1.125h-5.25a1.125 1.125 0 0 1-1.125-1.125v-8.25ZM3.75 16.125c0-.621.504-1.125 1.125-1.125h5.25c.621 0 1.125.504 1.125 1.125v2.25c0 .621-.504 1.125-1.125 1.125h-5.25a1.125 1.125 0 0 1-1.125-1.125v-2.25Z" />
        </svg>
        Hot Categories
    </div>
    <ul class="leading-10 text-lg">
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/reinforcement-learning/" class="hover:text-gray-300">Reinforcement Learning <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">4</span></a>
        </li>
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/nlp/" class="hover:text-gray-300">NLP <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">1</span></a>
        </li>
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/supply-chain/" class="hover:text-gray-300">Supply Chain <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">1</span></a>
        </li>
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/text/" class="hover:text-gray-300">Text <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">1</span></a>
        </li>
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/games/" class="hover:text-gray-300">Games <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">1</span></a>
        </li>
        
        
        
        

    </ul>

    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M9.568 3H5.25A2.25 2.25 0 0 0 3 5.25v4.318c0 .597.237 1.17.659 1.591l9.581 9.581c.699.699 1.78.872 2.607.33a18.095 18.095 0 0 0 5.223-5.223c.542-.827.369-1.908-.33-2.607L11.16 3.66A2.25 2.25 0 0 0 9.568 3Z" />
            <path stroke-linecap="round" stroke-linejoin="round" d="M6 6h.008v.008H6V6Z" />
        </svg>
        Top Tags
    </div>
    <div class="flex flex-wrap gap-2 text-lg leading-8 pt-3 pl-1">
        
        
        
        
        <a href="/tags/reinforcement-learning/"><span
                class="inline-block p-0 bg-gray-800 hover:bg-gray-900 border border-gray-800 text-gray-500 hover:text-gray-300 font-light mb-1 px-5 rounded-full hover:scale-105">Reinforcement Learning&nbsp;&nbsp;2</span></a>
        
        
        
        <a href="/tags/supply-chain/"><span
                class="inline-block p-0 bg-gray-800 hover:bg-gray-900 border border-gray-800 text-gray-500 hover:text-gray-300 font-light mb-1 px-5 rounded-full hover:scale-105">Supply Chain&nbsp;&nbsp;1</span></a>
        
        
        
        <a href="/tags/minecraft/"><span
                class="inline-block p-0 bg-gray-800 hover:bg-gray-900 border border-gray-800 text-gray-500 hover:text-gray-300 font-light mb-1 px-5 rounded-full hover:scale-105">Minecraft&nbsp;&nbsp;1</span></a>
        
        
        
        <a href="/tags/nlp/"><span
                class="inline-block p-0 bg-gray-800 hover:bg-gray-900 border border-gray-800 text-gray-500 hover:text-gray-300 font-light mb-1 px-5 rounded-full hover:scale-105">NLP&nbsp;&nbsp;1</span></a>
        
        
        
        
    </div>

   
    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M21.75 6.75v10.5a2.25 2.25 0 0 1-2.25 2.25h-15a2.25 2.25 0 0 1-2.25-2.25V6.75m19.5 0A2.25 2.25 0 0 0 19.5 4.5h-15a2.25 2.25 0 0 0-2.25 2.25m19.5 0v.243a2.25 2.25 0 0 1-1.07 1.916l-7.5 4.615a2.25 2.25 0 0 1-2.36 0L3.32 8.91a2.25 2.25 0 0 1-1.07-1.916V6.75" />
        </svg>
        Contact
    </div>
    <div class="flex flex-row gap-2">
        Emailï¼šmrugank.akarte@columbia.edu
    </div>
</aside>
        </div>

        <footer class="p-5 text-xl text-center mt-8 pt-8 pb-8 border-t border-gray-100/10">
    <div class="text-gray-500">
        
        &#xA9; 2025 by mrugankakarte All Rights Reserved.
        

        
        | <a class="hover:text-gray-100" href=" /en ">ðŸ‡ºðŸ‡¸EN</a>
        
    </div>
</footer>

        <div class="cookie-container text-center py-12 text-2xl font-thin text-gray-500">
  
  <p>
    We use cookies on this website to give you the best experience on our
    site and show you relevant ads. To find out more, read our
    <a href="/en/privacy/" class="text-red-600">privacy policy</a> and <a href="/en/terms/" class="text-red-600">cookie
      policy</a>.
  </p>
  
  
  <button class="cookie-btn w-32 h-12 lg:h-22 mt-5 py-2 bg-red-600 text-white rounded-full hover:scale-110">
    Okay
  </button>
</div>
<script src="/js/cookie.js"></script>

    </div>
</body>

</html>