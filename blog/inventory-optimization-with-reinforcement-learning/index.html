<!DOCTYPE html>
<html lang="en-us"
    dir="ltr"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no, maximum-scale=1">
    <title>
    
    Inventory Optimization: MDP vs RL - Mrugank M Akarte
    
</title>
    
    
    
    
    
    
    
    
    <meta name="keywords" content="Mrugank, Mrugank Akarte">
    <meta name="description" content="Reinforcement Learning Application">
    <link rel="canonical" href="http://localhost:1313/blog/inventory-optimization-with-reinforcement-learning/" />
    <link rel="icon" href="/favicon.ico?v=1741233249" type="image/x-icon">
    
<link rel="stylesheet" href="/css/app.css">
    
<script src="/js/main.js"></script>


<script defer src="https://cdn.jsdelivr.net/npm/alpinejs@3.13.10/dist/cdn.min.js"></script>

    
    
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=%2a%2a%2a%2a%2a%2a" crossorigin="anonymous"></script>
    

    
    
    <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', '******');
    </script>
    

    
    
    <script type="text/javascript"
        src="https://platform-api.sharethis.com/js/sharethis.js#property=&product=sticky-share-buttons"
        async="async"></script>
    
</head><body>
    <div class="
        mx-auto max-w-[calc(120rem)]
        min-h-screen
        2xl:px-[calc(16rem)]
        xl:px-24
        md:px-8
        px-4
    ">

        <div x-data="{ openMenu: false }" class="relative">
    <nav class="flex flex-1 flex-col lg:flex-row items-center justify-between">
        <a href="/">
            <img src="/favicon.ico?v=1741233249" alt="site logo"
                class="w-16 h-16 my-5 p-1 bg-gray-100 rounded-full cursor-pointer hover:scale-110" />
        </a>
        <div class="hidden lg:block" :class="{'hidden': !openMenu}">
            






<ul
    class="flex flex-col lg:flex-row justify-end mt-2 sm:mt-5 mb-5 pb-2 font-light text-xl lg:text-2xl gap-5 lg:gap-1 text-center">
    








<li>
    <a    class="px-5 lg:px-10 py-3 font-light hover:border-b-2 hover:border-red-500"     href="/"  >Home</a>
    
</li>







<li>
    <a    class="px-5 lg:px-10 py-3 font-light hover:border-b-2 hover:border-red-500"     href="/tags/"  >Tags</a>
    
</li>







<li>
    <a    class="px-5 lg:px-10 py-3 font-light hover:border-b-2 hover:border-red-500"    >Contact</a>
    
</li>


</ul>




        </div>
    </nav>
    <div class="absolute top-8 right-5 flex items-center lg:hidden">
        
        <button @click="openMenu = !openMenu" type="button"
            class="relative inline-flex items-center justify-center rounded-md p-2 text-gray-400 hover:bg-gray-800 hover:text-gray-100 focus:outline-hidden focus:ring-2 focus:ring-inset focus:ring-white"
            aria-controls="mobile-menu" aria-expanded="openMenu">
            
            <svg x-show="!openMenu" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                stroke="currentColor" aria-hidden="true">
                <path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" />
            </svg>
            
            <svg x-show="openMenu" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                stroke="currentColor" aria-hidden="true">
                <path stroke-linecap="round" stroke-linejoin="round" d="M6 18L18 6M6 6l12 12" />
            </svg>
        </button>
    </div>
</div>

        <header class="flex flex-col w-full items-center justify-center text-white pt-8 pb-8">
    <div class="w-full">
        <div class="flex flex-1 flex-row justify-between">
            <h2 class="w-full text-center text-3xl sm:text-5xl font-crimson font-bold tracking-tight text-gray-300">
                <a href="http://localhost:1313/">Mrugank M Akarte</a>
            </h2>
        </div>
        <p
            class="w-full text-center pl-1 pb-4 sm:pt-3 sm:pb-0 font-crimson font-normal text-xl sm:text-2xl leading-8 text-gray-500">
            Personal Blog</p>
    </div>

    <div class="relative w-9/12 lg:w-1/2 h-12 my-5">
        <form action="/en/search" method="get">
            <input
                class="bg-gray-800 placeholder:italic placeholder:text-gray-600 w-full h-12 rounded-full mt-1 pl-5 pr-5 border border-gray-800 text-gray-100"
                placeholder='Input Keywords...' type="text" name="q" id="search-query" />

            <button
                class="absolute inset-y-2 right-1 w-28 h-10 font-light bg-gray-900 hover:bg-red-500 text-gray-500 hover:text-gray-100 rounded-full cursor-pointer"
                type="submit">Search</button>
        </form>
    </div>

    
    <div class="w-full flex flex-row justify-start text-gray-500 text-lg px-1 border-l-4 border-l-red-500">
        <ul class="flex flex-row gap-x-2">
            <li class="">
                <a href="/" class="hover:text-gray-100">Home</a>
            </li>
            
            <li>
                &gt;&nbsp;&nbsp;<a href="/blog/inventory-optimization-with-reinforcement-learning/" class="hover:text-gray-100">Inventory Optimization: MDP vs RL</a>
            </li>
            
        </ul>
    </div>
    <div class="w-full h-2 border-b border-b-gray-600/50 border-dashed font-light text-gray-300">
    </div>
    

</header>

        <div class="
            flex flex-col overflow-hidden
            xl:px-0
            lg:flex-row lg:space-x-8
        ">
            <main class="w-full overflow-hidden">
                

<article class="single-article">
    
    <div class="group relative">
        <h1 class="text-3xl font-medium leading-10 text-gray-400 hover:text-gray-100">
            <a href="/blog/inventory-optimization-with-reinforcement-learning/">
                Inventory Optimization: MDP vs RL
            </a>
        </h1>
        <time datetime="2025-03-16" class="flex items-center py-2 text-xl text-gray-600">
            2019-06-04 13:00
            &nbsp;&nbsp;|&nbsp;&nbsp;7 minute read
        </time>

        <div
            class="mt-1 lg:pb-10 px-2 text-2xl leading-10 font-thin text-gray-500 overflow-hidden break-words article-body">
            <p>Inventory Optimization is a task of maximizing revenue by taking into account the capital investment, warehouse capacity, supply and demand of stock, leadtime and backordering of stocks. This problem has been well researched and is usually presented in form of a Markov Decision Process (MDP). The (s, S) policy is proved to be a optimal solution for such problems.[s: Reorder stock level, S: Target stock level].</p>
<p>Markov Decision Process (MDP) provide a framework to model decision making process where outcomes are partly random and partly under the control of decision maker. The learner or decision maker is called an <em>agent</em>. The agent interacts with the <em>environment</em> which comprises of everything except the agent.</p>
<p>The process flow in a MDP is as follows:</p>
<ol>
<li>We get the current state from the environment</li>
<li>Agent takes action from all possible actions for the given state</li>
<li>Environment reacts to the action taken by agent and present the reward and next state</li>
<li>We modify the agents policy based on the rewards received</li>
<li>Agent again acts for the new state using the modified policy</li>
</ol>
<p>This process continues until the task is accomplished.</p>
<h2 id="inventory-optimization-with-mdp">Inventory Optimization with MDP</h2>
<p>Let&rsquo;s try to understand how to model inventory optimization problem into MDP.</p>
<p><img src="/blog/invopt-rl/invopt-ex1.PNG" alt="invopt-ex1" title="Inventory Problem">(Source: Andrew Schaefer, EWO Seminar PPT, Oct 2006)</p>
<p>In terms of MDP,</p>
<ul>
<li>
<p>The <em>states</em> are amount of stock available on hand at start of each time period. Let&rsquo;s assume the max inventory of our warehouse is M, then all the possible state values can be <em>S<sub>t</sub> = 0,1,2,3&hellip;.M</em></p>
</li>
<li>
<p>The <em>actions</em> are amount of stock that can be ordered at each time period. The possible values for action can be <em>a<sub>t</sub> = 0,1,2,3&hellip;..M-s<sub>t</sub></em></p>
</li>
<li>
<p>The <em>rewards</em> are expected net income for taking an action in a state. For inventory problem we have 3 costs associated to it as shown above.
- Ordering cost
- Holding cost
- Revenue generated after meeting the customer demand
Thus,</p>
<pre><code>total reward = Expected revenue - order cost - holding cost
</code></pre>
</li>
<li>
<p><em>Transition probabilites</em> govern how the state changes as the actions are taken over time. <img src="/blog/invopt-rl/invopt-transprob.PNG" alt="invopt-transprob" title="Transition probabilites for inventory problem"></p>
</li>
</ul>
<p>(<em>This transition probabilities are for a case where backorders are not accounted for</em>)</p>
<p>The obejective is <em>How much stock should be ordered at each time period such that my expected profits are maximized over time</em>. To solve this problem we make few assumptions:</p>
<ol>
<li>Maximum allowable inventory is M and units can be backordered if sufficient stock is not available to met the customer demand.</li>
<li>Demand is random with uniform probability distribution and the values can be 1,2,3,4&hellip;.M</li>
<li>The inventory (state) is counted at the beginning of each time period and a decision is then made to raise the stocks to M.</li>
<li>The ordered stock does not have any leadtime and are delivered instanteneously.</li>
<li>Customer demand is met at the end of each time period.</li>
</ol>
<p>With above assumptions, we use (s, S) policy to determine the amount of stock to reorder. In other words, we the stock falls below <em>s</em>, we order the amount such that the inventory is filled up to <em>S</em>.</p>
<p>Let&rsquo;s take an example:</p>
<p>We have maximum inventory size of 100 units, reorder level (s) is 40 units, restock level (S) = 100, it is (40, 100) policy. We haven&rsquo;t found the best policy here, which can be found out using value iteration and policy iteration methods. Order cost is 2 per unit, holding cost is 1 per unit, penalty for backorder is 2 per unit, revenue generated is 8 per unit. Check this <a href="/files/invopt-mdp.html">notebook</a> for complete code.</p>
<p>The average cost per episode with 100 timesteps is 180. The following diagram shows the state vs timestep. Notice, the state value doesn&rsquo;t go back to 100 in next state as mentioned in our policy, this is because the demand is met at the end of the time period which is subtracted.
<img src="/blog/invopt-rl/invopt-mdp.png" alt="invopt-mpd"></p>
<p>Let&rsquo;s use this as a baseline to test our model trained using Reinforcement Learning for Inventory Optimization.</p>
<h2 id="inventory-optimization-with-reinforcement-learning">Inventory Optimization with Reinforcement Learning</h2>
<p>The limitations of MDP is that as the problem size increases, i.e. increase in state and action size, it becomes coputationally difficult to solve the MDPs. Also for each state and action pair we need transition probability which may not be available in real world problem.</p>
<p>Using reinforcement learning removes the need of transition probabilities, and function approximators like neural networks can be used to model enormous state and action space. It is also easier to implement than MDPs.</p>
<p>We create two model types <strong>&lsquo;withdemand&rsquo;</strong> and <strong>&rsquo;nodemand&rsquo;</strong>. In model type <em>withdemand</em>, the agent is provided with the values of current demand along with current <em>state values</em> to predict the action. Whereas in model type <em>nodemand</em>, the current demand is not disclosed to the agent and the predictions are made based on only current <em>state values</em>. For both model type other information remains the same as defined in MDP. Please check this <a href="/files/invopt-rl1.html">notebook</a> for full code.</p>
<p>Following plot shows Inventory level vs Timestep for <em>nodemand</em> model type. After training the agent for 500 episodes with 100 timestes each, the average cost per episode with 100 timesteps is 180. From the plot we can see that agent is struggling to keep the backorders and state value to minimum as the demand is unknown.</p>
<p><img src="/blog/invopt-rl/invopt-nodemand.png" alt="nodemand" title="Model:nodemand"></p>
<p>Following graph shows Inventory level vs Timestep for <em>withdemand</em> model type. After training the agent for 500 episodes with 100 timestes each, the average cost per episode with 100 timesteps is 280. The agent is trying to keep the <em>state</em> value close to zero to keep the holding cost to minimum and hence maximizing the rewards.</p>
<p><img src="/blog/invopt-rl/invopt-withdemand.png" alt="withdemand" title="Model:withdemand"></p>
<p>These models were sucessful in increasing the average profits over a period of time compared to MDP.</p>
<h3 id="introducing-lead-time-for-delivery-of-stock">Introducing lead time for delivery of stock</h3>
<p>Let&rsquo;s up the game by adding leadtime to the above problem. Assume that there is a lead time of 3 time periods, i.e the action taken at time period <em>t</em> will reach the warehouse at time period <em>t+3</em>. The demand is random with uniform distribution but, it limited to maximum quantity of 30 unit at each time period. In such cases the maximum value of inventory can exceed the value M, thus they are usually modeled as infinite warehouse capacity, i.e there is no upper limit to stocks that can be stored in a warehouse. Although it doesn&rsquo;t sound correct, but when we train our agent, the agent realizes that keeping excess stocks reduces his profits and thus will try to keep the stock on hand to minimum.</p>
<p>Following graph shows <strong><em>Current state vs Timeperiod</em></strong> for an agent trained for 300 episodes with 500 timesteps each. The current state and demand are given as input to agent to predict the action. The average profit per episode is 30. This is very low as compared to previous solutions, this is because of two main reasons. One, the demand is random and second the agent doesn&rsquo;t know that there is a lead time of 3 units for the actions taken. Hence, it becomes very difficult to predict the actions so that holding costs are minimized to maximize the profits. The <strong>red line</strong> indicates the stocks on hand and <strong>orange line</strong> indicates the action taken (stock ordered) at time period <em>t</em>.
<img src="/blog/invopt-rl/invopt-rl_leadtime3.png" alt="invopt-rl_leadtime"></p>
<p>The following graph if for the same agent trained for 400 episodes with 500 timesteps each. It looks like the agent here is trying to keep the order cost to minimum and is therefore ordering large quantities of stock, thus ends up with high on-hand inventory.</p>
<p><img src="/blog/invopt-rl/invopt-rl_leadtime2.png" alt="invopt-rl_leadtime"></p>
<p>The following graph if for the same agent trained for 500 episodes with 500 timesteps each. It is visible that agent has realized it is keep a large stock on hand and thus tries to reduce it. The maximum stock on-hand dropped from 250 to 150, which show that agent partially successful in reducing the on-hand inventory. But now many of the orders are getting backlogged.</p>
<p><img src="/blog/invopt-rl/invopt-rl_leadtime.png" alt="invopt-rl_leadtime"></p>
<p>There are lots of areas to improve the results further, like giving the <em>stocks in transit</em> as input to our agent along with the current <em>state</em> and <em>demand</em>, testing different hyperparameters for neural net used in our agent, training the agent for longer duration. Complete code can be found <a href="/files/invopt-rl_leadtime.html">here</a>
This is just a small example of how reinforcement learning can be used to optimize inventory and maximize the profits in real world.</p>

        </div>
    </div>
    <div class="text-gray-500 text-lg">
        Page link:&nbsp;<a href="http://localhost:1313/blog/inventory-optimization-with-reinforcement-learning/"
            class="border-b border-b-gray-500 hover:text-gray-400">http://localhost:1313/blog/inventory-optimization-with-reinforcement-learning/</a>
    </div>
    
    
        <div class="my-10 py-5 border-t border-dashed border-t-white/10 text-xl">
  <div id="disqus_thread"></div>
  <script>
      

      

      (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://guangmean.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments.</a></noscript>
</div>
    
</article>


            </main>

            <aside id="sidebar" class="aside-container">

    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M21 8.25c0-2.485-2.099-4.5-4.688-4.5-1.935 0-3.597 1.126-4.312 2.733-.715-1.607-2.377-2.733-4.313-2.733C5.1 3.75 3 5.765 3 8.25c0 7.22 9 12 9 12s9-4.78 9-12Z" />
        </svg>
        About Me
    </div>

    <img src="/image/logo.webp?v=1741233249" class="w-80 self-center" alt="Logo" />

    <p class="leading-8 text-center text-lg font-light mt-3">
        
    </p>

    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M9 12h3.75M9 15h3.75M9 18h3.75m3 .75H18a2.25 2.25 0 0 0 2.25-2.25V6.108c0-1.135-.845-2.098-1.976-2.192a48.424 48.424 0 0 0-1.123-.08m-5.801 0c-.065.21-.1.433-.1.664 0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75 2.25 2.25 0 0 0-.1-.664m-5.8 0A2.251 2.251 0 0 1 13.5 2.25H15c1.012 0 1.867.668 2.15 1.586m-5.8 0c-.376.023-.75.05-1.124.08C9.095 4.01 8.25 4.973 8.25 6.108V8.25m0 0H4.875c-.621 0-1.125.504-1.125 1.125v11.25c0 .621.504 1.125 1.125 1.125h9.75c.621 0 1.125-.504 1.125-1.125V9.375c0-.621-.504-1.125-1.125-1.125H8.25ZM6.75 12h.008v.008H6.75V12Zm0 3h.008v.008H6.75V15Zm0 3h.008v.008H6.75V18Z" />
        </svg>
        Latest Post
    </div>

    <ul class="text-lg">
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/project-minerl/" class="py-5 hover:text-gray-300">Project MineRL</a>
        </li>
        
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/inventory-optimization-with-reinforcement-learning/" class="py-5 hover:text-gray-300">Inventory Optimization: MDP vs RL</a>
        </li>
        
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/deep-q-learning/" class="py-5 hover:text-gray-300">Deep Q-Learning</a>
        </li>
        
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/q-learning/" class="py-5 hover:text-gray-300">Q-Learning</a>
        </li>
        
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/reinforcement-learning/" class="py-5 hover:text-gray-300">Reinforcement Learning</a>
        </li>
        
        
    </ul>

    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M2.25 7.125C2.25 6.504 2.754 6 3.375 6h6c.621 0 1.125.504 1.125 1.125v3.75c0 .621-.504 1.125-1.125 1.125h-6a1.125 1.125 0 0 1-1.125-1.125v-3.75ZM14.25 8.625c0-.621.504-1.125 1.125-1.125h5.25c.621 0 1.125.504 1.125 1.125v8.25c0 .621-.504 1.125-1.125 1.125h-5.25a1.125 1.125 0 0 1-1.125-1.125v-8.25ZM3.75 16.125c0-.621.504-1.125 1.125-1.125h5.25c.621 0 1.125.504 1.125 1.125v2.25c0 .621-.504 1.125-1.125 1.125h-5.25a1.125 1.125 0 0 1-1.125-1.125v-2.25Z" />
        </svg>
        Hot Categories
    </div>
    <ul class="leading-10 text-lg">
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/reinforcement-learning/" class="hover:text-gray-300">Reinforcement Learning <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">4</span></a>
        </li>
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/games/" class="hover:text-gray-300">Games <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">1</span></a>
        </li>
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/nlp/" class="hover:text-gray-300">NLP <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">1</span></a>
        </li>
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/supply-chain/" class="hover:text-gray-300">Supply Chain <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">1</span></a>
        </li>
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/text/" class="hover:text-gray-300">Text <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">1</span></a>
        </li>
        
        
        
        

    </ul>

    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M9.568 3H5.25A2.25 2.25 0 0 0 3 5.25v4.318c0 .597.237 1.17.659 1.591l9.581 9.581c.699.699 1.78.872 2.607.33a18.095 18.095 0 0 0 5.223-5.223c.542-.827.369-1.908-.33-2.607L11.16 3.66A2.25 2.25 0 0 0 9.568 3Z" />
            <path stroke-linecap="round" stroke-linejoin="round" d="M6 6h.008v.008H6V6Z" />
        </svg>
        Top Tags
    </div>
    <div class="flex flex-wrap gap-2 text-lg leading-8 pt-3 pl-1">
        
        
        
        
        <a href="/tags/reinforcement-learning/"><span
                class="inline-block p-0 bg-gray-800 hover:bg-gray-900 border border-gray-800 text-gray-500 hover:text-gray-300 font-light mb-1 px-5 rounded-full hover:scale-105">Reinforcement Learning&nbsp;&nbsp;2</span></a>
        
        
        
        <a href="/tags/minecraft/"><span
                class="inline-block p-0 bg-gray-800 hover:bg-gray-900 border border-gray-800 text-gray-500 hover:text-gray-300 font-light mb-1 px-5 rounded-full hover:scale-105">Minecraft&nbsp;&nbsp;1</span></a>
        
        
        
        <a href="/tags/nlp/"><span
                class="inline-block p-0 bg-gray-800 hover:bg-gray-900 border border-gray-800 text-gray-500 hover:text-gray-300 font-light mb-1 px-5 rounded-full hover:scale-105">NLP&nbsp;&nbsp;1</span></a>
        
        
        
        <a href="/tags/supply-chain/"><span
                class="inline-block p-0 bg-gray-800 hover:bg-gray-900 border border-gray-800 text-gray-500 hover:text-gray-300 font-light mb-1 px-5 rounded-full hover:scale-105">Supply Chain&nbsp;&nbsp;1</span></a>
        
        
        
        
    </div>

   
    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M21.75 6.75v10.5a2.25 2.25 0 0 1-2.25 2.25h-15a2.25 2.25 0 0 1-2.25-2.25V6.75m19.5 0A2.25 2.25 0 0 0 19.5 4.5h-15a2.25 2.25 0 0 0-2.25 2.25m19.5 0v.243a2.25 2.25 0 0 1-1.07 1.916l-7.5 4.615a2.25 2.25 0 0 1-2.36 0L3.32 8.91a2.25 2.25 0 0 1-1.07-1.916V6.75" />
        </svg>
        Contact
    </div>
    <div class="flex flex-row gap-2">
        Email：mrugank.akarte@columbia.edu
    </div>
</aside>
        </div>

        <footer class="p-5 text-xl text-center mt-8 pt-8 pb-8 border-t border-gray-100/10">
    <div class="text-gray-500">
        
        &#xA9; 2025 by mrugankakarte All Rights Reserved.
        

        
        | <a class="hover:text-gray-100" href=" /en ">🇺🇸EN</a>
        
    </div>
</footer>

        <div class="cookie-container text-center py-12 text-2xl font-thin text-gray-500">
  
  <p>
    We use cookies on this website to give you the best experience on our
    site and show you relevant ads. To find out more, read our
    <a href="/en/privacy/" class="text-red-600">privacy policy</a> and <a href="/en/terms/" class="text-red-600">cookie
      policy</a>.
  </p>
  
  
  <button class="cookie-btn w-32 h-12 lg:h-22 mt-5 py-2 bg-red-600 text-white rounded-full hover:scale-110">
    Okay
  </button>
</div>
<script src="/js/cookie.js"></script>

    </div>
</body>

</html>