<!DOCTYPE html>
<html lang="en-us"
    dir="ltr"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no, maximum-scale=1">
    <title>
    
    Deep Q-Learning - Mrugank M Akarte
    
</title>
    
    
    
    
    
    
    
    
    <meta name="keywords" content="Mrugank, Mrugank Akarte">
    <meta name="description" content="Reinforcement Learning">
    <link rel="canonical" href="http://localhost:1313/blog/deep-q-learning/" />
    <link rel="icon" href="/favicon.ico?v=1741233249" type="image/x-icon">
    
<link rel="stylesheet" href="/css/app.css">
    
<script src="/js/main.js"></script>


<script defer src="https://cdn.jsdelivr.net/npm/alpinejs@3.13.10/dist/cdn.min.js"></script>

    
    
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=%2a%2a%2a%2a%2a%2a" crossorigin="anonymous"></script>
    

    
    
    <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', '******');
    </script>
    

    
    
    <script type="text/javascript"
        src="https://platform-api.sharethis.com/js/sharethis.js#property=&product=sticky-share-buttons"
        async="async"></script>
    
</head><body>
    <div class="
        mx-auto max-w-[calc(120rem)]
        min-h-screen
        2xl:px-[calc(16rem)]
        xl:px-24
        md:px-8
        px-4
    ">

        <div x-data="{ openMenu: false }" class="relative">
    <nav class="flex flex-1 flex-col lg:flex-row items-center justify-between">
        <a href="/">
            <img src="/favicon.ico?v=1741233249" alt="site logo"
                class="w-16 h-16 my-5 p-1 bg-gray-100 rounded-full cursor-pointer hover:scale-110" />
        </a>
        <div class="hidden lg:block" :class="{'hidden': !openMenu}">
            






<ul
    class="flex flex-col lg:flex-row justify-end mt-2 sm:mt-5 mb-5 pb-2 font-light text-xl lg:text-2xl gap-5 lg:gap-1 text-center">
    








<li>
    <a    class="px-5 lg:px-10 py-3 font-light hover:border-b-2 hover:border-red-500"     href="/"  >Home</a>
    
</li>







<li>
    <a    class="px-5 lg:px-10 py-3 font-light hover:border-b-2 hover:border-red-500"     href="/tags/"  >Tags</a>
    
</li>







<li>
    <a    class="px-5 lg:px-10 py-3 font-light hover:border-b-2 hover:border-red-500"    >Contact</a>
    
</li>


</ul>




        </div>
    </nav>
    <div class="absolute top-8 right-5 flex items-center lg:hidden">
        
        <button @click="openMenu = !openMenu" type="button"
            class="relative inline-flex items-center justify-center rounded-md p-2 text-gray-400 hover:bg-gray-800 hover:text-gray-100 focus:outline-hidden focus:ring-2 focus:ring-inset focus:ring-white"
            aria-controls="mobile-menu" aria-expanded="openMenu">
            
            <svg x-show="!openMenu" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                stroke="currentColor" aria-hidden="true">
                <path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" />
            </svg>
            
            <svg x-show="openMenu" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                stroke="currentColor" aria-hidden="true">
                <path stroke-linecap="round" stroke-linejoin="round" d="M6 18L18 6M6 6l12 12" />
            </svg>
        </button>
    </div>
</div>

        <header class="flex flex-col w-full items-center justify-center text-white pt-8 pb-8">
    <div class="w-full">
        <div class="flex flex-1 flex-row justify-between">
            <h2 class="w-full text-center text-3xl sm:text-5xl font-crimson font-bold tracking-tight text-gray-300">
                <a href="http://localhost:1313/">Mrugank M Akarte</a>
            </h2>
        </div>
        <p
            class="w-full text-center pl-1 pb-4 sm:pt-3 sm:pb-0 font-crimson font-normal text-xl sm:text-2xl leading-8 text-gray-500">
            Personal Blog</p>
    </div>

    <div class="relative w-9/12 lg:w-1/2 h-12 my-5">
        <form action="/en/search" method="get">
            <input
                class="bg-gray-800 placeholder:italic placeholder:text-gray-600 w-full h-12 rounded-full mt-1 pl-5 pr-5 border border-gray-800 text-gray-100"
                placeholder='Input Keywords...' type="text" name="q" id="search-query" />

            <button
                class="absolute inset-y-2 right-1 w-28 h-10 font-light bg-gray-900 hover:bg-red-500 text-gray-500 hover:text-gray-100 rounded-full cursor-pointer"
                type="submit">Search</button>
        </form>
    </div>

    
    <div class="w-full flex flex-row justify-start text-gray-500 text-lg px-1 border-l-4 border-l-red-500">
        <ul class="flex flex-row gap-x-2">
            <li class="">
                <a href="/" class="hover:text-gray-100">Home</a>
            </li>
            
            <li>
                &gt;&nbsp;&nbsp;<a href="/blog/deep-q-learning/" class="hover:text-gray-100">Deep Q-Learning</a>
            </li>
            
        </ul>
    </div>
    <div class="w-full h-2 border-b border-b-gray-600/50 border-dashed font-light text-gray-300">
    </div>
    

</header>

        <div class="
            flex flex-col overflow-hidden
            xl:px-0
            lg:flex-row lg:space-x-8
        ">
            <main class="w-full overflow-hidden">
                

<article class="single-article">
    
    <div class="group relative">
        <h1 class="text-3xl font-medium leading-10 text-gray-400 hover:text-gray-100">
            <a href="/blog/deep-q-learning/">
                Deep Q-Learning
            </a>
        </h1>
        <time datetime="2025-03-16" class="flex items-center py-2 text-xl text-gray-600">
            2019-05-18 10:00
            &nbsp;&nbsp;|&nbsp;&nbsp;5 minute read
        </time>

        <div
            class="mt-1 lg:pb-10 px-2 text-2xl leading-10 font-thin text-gray-500 overflow-hidden break-words article-body">
            <h1 id="deep-q-learning">Deep Q-learning</h1>
<p>We introduce deep neural networks to do the Q-Learning, hence the name Deep Q-Learning. Instead of calculating Q-values for each state-action pair, we calculate Q-values for all actions given the state and then select the action with maximum q-value. This concept was first introduced in <a href="https://arxiv.org/abs/1312.5602">Playing Atari with Deep Reinforcement Learning</a> paper. The authors show that they were able to surpass human experts on three out of seven Atari games tested using deep neural networks to solve these reinforcement problems.</p>
<p>The idea in the paper is that, you capture the Atari screen, use convolutional neural networks to extract the features of the game and then calculate the q-values for each action. Then action with maximum q-value is taken and reward, next state are observed. This data (current state, action taken, reward received, next state) are stored in a fixed sized buffer called <strong><em>replay memory</em></strong>. A batch of random samples with uniform distribution are drawn from this memory and then model is updated. The actions taken by our neural network model are considered as predictions and true actions are calculated using the bellman equation. The error between true value and predictions are calcluated as mean squared error and the model is optimized using this error.</p>
<p><img src="/blog/dqn/ql-dqnalgo.PNG" alt="ql-dqnalgo" title="Deep Q-Learning Algorithm">(<em>Source: Playing Atari with Deep Reinfiorcement Learning, Dec 2013</em>)</p>
<p>Let&rsquo;s try to understand what exactly is happening&hellip;</p>
<p>Similar to Q-Learning, we get the state, execute the action using Îµ-greedy method and observe reward and next state. We then store these observations into a replay memory and use them to update the weights of our neural network which is used to take action. The neural network maps the state to the actions. In next step we sample the observations randomly from the replay memory and the reason we don&rsquo;t take consecutive observations is that learning is inefficient due to high correlation between the samples. Randomizing the samples break this correlation which helps to reduce the variation of the updates for neural network.</p>
<p>Another reason is that current parameters determine the next data sample that the parameters are trained on. For example, if the maximizing action is to move left then the training samples will be dominated by samples from the left-hand side; if the maximizing action then switches to the right then the training distribution will also switch. This can lead to high divergence in parameters and agent can get stuck in local minima. When randomized samples are used, this behaviour is averaged over many previous states thus smoothing out the learning.</p>
<p>Another confusing thing here is in calculation for values of ground truth. We are using the same network to calculate the <em>y<sub>i</sub></em> and also for prediction. It&rsquo;s like chasing your own tail. At everytime step we use our neural net to calculate the ground truth for the sampled states and also predict the Q-values for the same, update the network and repeat. So at each timestep we are changing our parameters which means the groud truth also changes. What this means is that everytime the model tries to reach the ground truth of a state, it changes to a new value. Apparently the model works.</p>
<p>One way to mitigate this problem is by using two neural nets (<em>DQN network</em> and <em>Target network</em>) say with parameters (Î¸ and Î¸*). Initially we copy the parameters from DQN netwrok to Target network (Î¸ -&gt; Î¸*), but instead of updating the parameters of target network at each timestep we update them after some fixed time step. By updating the target parameter I mean we copy the new parameter values from DQN network to Targent network after fixed timesteps <em>t</em>. We then use the DQN network for predictions and Target network to calculate the ground truth.</p>
<p>Another solution to above problem is given in <a href="https://arxiv.org/abs/1509.06461">Deep Reinforcement learning using Double DQN</a>. The idea is that when we compute the ground truth, we use two networks to decouple the selection from evaluation. So the equation in DQN<br>
<img src="/blog/dqn/dqn-qtargetdqn.PNG" alt="dqn-qtargetdqn"></p>
<p>changes to</p>
<p><img src="/blog/dqn/dqn-qtargetddqn.PNG" alt="dqn-qtargetdqn"> (<strong>Notice the Î¸&rsquo;</strong>).</p>
<p>This is done because it was found that when same network is used to select the best action and also for evaluation, the DQN tends to over-estimate values. Hence, we use the DQN network to select best action to take for next state (inner Q-value) <em>argmax Q(S<sub>t+1</sub>, a; Î¸<sub>t</sub>)</em> and the Target network to calculate <em>Q(S<sub>t+1</sub>, argmax Q(S<sub>t+1</sub>, a; Î¸<sub>t</sub>); Î¸&rsquo;<sub>t</sub>)</em> the ground truth value of taking that action at next state.</p>
<p>Let&rsquo;s see the DQN in action for <em>Cart and Pole</em> game&hellip;</p>
<p>1.<strong>Agent at the beginning of training&hellip;(Random Actions)</strong></p>

<video width="320" height="240" autoplay loop>
  <source src="/blog/dqn/dqn-cartpole_ep0.mp4" type="video/mp4">
</video>
<p>2.<strong>Agent after trained for 100 episodes</strong></p>

<video width="320" height="240" autoplay loop>
  <source src="/blog/dqn/dqn-cartpole_ep100.mp4" type="video/mp4">
</video>
<p>3.<strong>Agent after trained for 200 episodes</strong></p>

<video width="320" height="240" autoplay loop>
  <source src="/blog/dqn/dqn-cartpole_ep200.mp4" type="video/mp4">
</video>
<p>Isn&rsquo;t it amazing!!! Just a few lines of code and our agent can balance a pole on a cart reasonably well. Infact this is not just limited to <em>Cart and Pole Game</em>, you can even train our agent to play some old school Atari games like SpaceInvaders, PingPong, Breakout and many more. But to get good results you need to train it for a long time. <a href="/files/DQN-Cartpole.html">Here</a> is the link for the complete code for running DQN for Cart and Pole.</p>
<p>In the next article, we will look at <strong><em>Policy Gradient Methods</em></strong> and solve the same <em>Cart and Pole</em> game to compare the results with <em>Deep Q-Learning</em>.</p>

        </div>
    </div>
    <div class="text-gray-500 text-lg">
        Page link:&nbsp;<a href="http://localhost:1313/blog/deep-q-learning/"
            class="border-b border-b-gray-500 hover:text-gray-400">http://localhost:1313/blog/deep-q-learning/</a>
    </div>
    
    
        <div class="my-10 py-5 border-t border-dashed border-t-white/10 text-xl">
  <div id="disqus_thread"></div>
  <script>
      

      

      (function() { 
      var d = document, s = d.createElement('script');
      s.src = 'https://guangmean.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments.</a></noscript>
</div>
    
</article>


            </main>

            <aside id="sidebar" class="aside-container">

    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M21 8.25c0-2.485-2.099-4.5-4.688-4.5-1.935 0-3.597 1.126-4.312 2.733-.715-1.607-2.377-2.733-4.313-2.733C5.1 3.75 3 5.765 3 8.25c0 7.22 9 12 9 12s9-4.78 9-12Z" />
        </svg>
        About Me
    </div>

    <img src="/image/logo.webp?v=1741233249" class="w-80 self-center" alt="Logo" />

    <p class="leading-8 text-center text-lg font-light mt-3">
        
    </p>

    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M9 12h3.75M9 15h3.75M9 18h3.75m3 .75H18a2.25 2.25 0 0 0 2.25-2.25V6.108c0-1.135-.845-2.098-1.976-2.192a48.424 48.424 0 0 0-1.123-.08m-5.801 0c-.065.21-.1.433-.1.664 0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75 2.25 2.25 0 0 0-.1-.664m-5.8 0A2.251 2.251 0 0 1 13.5 2.25H15c1.012 0 1.867.668 2.15 1.586m-5.8 0c-.376.023-.75.05-1.124.08C9.095 4.01 8.25 4.973 8.25 6.108V8.25m0 0H4.875c-.621 0-1.125.504-1.125 1.125v11.25c0 .621.504 1.125 1.125 1.125h9.75c.621 0 1.125-.504 1.125-1.125V9.375c0-.621-.504-1.125-1.125-1.125H8.25ZM6.75 12h.008v.008H6.75V12Zm0 3h.008v.008H6.75V15Zm0 3h.008v.008H6.75V18Z" />
        </svg>
        Latest Post
    </div>

    <ul class="text-lg">
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/project-minerl/" class="py-5 hover:text-gray-300">Project MineRL</a>
        </li>
        
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/inventory-optimization-with-reinforcement-learning/" class="py-5 hover:text-gray-300">Inventory Optimization: MDP vs RL</a>
        </li>
        
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/deep-q-learning/" class="py-5 hover:text-gray-300">Deep Q-Learning</a>
        </li>
        
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/q-learning/" class="py-5 hover:text-gray-300">Q-Learning</a>
        </li>
        
        
        
        <li class="leading-10 line-clamp-1 mb-3 font-light border-b border-b-white/10 border-dashed">
            <a href="/blog/reinforcement-learning/" class="py-5 hover:text-gray-300">Reinforcement Learning</a>
        </li>
        
        
    </ul>

    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M2.25 7.125C2.25 6.504 2.754 6 3.375 6h6c.621 0 1.125.504 1.125 1.125v3.75c0 .621-.504 1.125-1.125 1.125h-6a1.125 1.125 0 0 1-1.125-1.125v-3.75ZM14.25 8.625c0-.621.504-1.125 1.125-1.125h5.25c.621 0 1.125.504 1.125 1.125v8.25c0 .621-.504 1.125-1.125 1.125h-5.25a1.125 1.125 0 0 1-1.125-1.125v-8.25ZM3.75 16.125c0-.621.504-1.125 1.125-1.125h5.25c.621 0 1.125.504 1.125 1.125v2.25c0 .621-.504 1.125-1.125 1.125h-5.25a1.125 1.125 0 0 1-1.125-1.125v-2.25Z" />
        </svg>
        Hot Categories
    </div>
    <ul class="leading-10 text-lg">
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/reinforcement-learning/" class="hover:text-gray-300">Reinforcement Learning <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">4</span></a>
        </li>
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/supply-chain/" class="hover:text-gray-300">Supply Chain <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">1</span></a>
        </li>
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/text/" class="hover:text-gray-300">Text <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">1</span></a>
        </li>
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/games/" class="hover:text-gray-300">Games <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">1</span></a>
        </li>
        
        
        
        
        
        <li class="mb-1 border-b border-b-gray-900 border-dashed font-light">
            <a href="/categories/nlp/" class="hover:text-gray-300">NLP <span
                    class="ml-2 px-2 bg-gray-800 rounded-full text-gray-500">1</span></a>
        </li>
        
        
        
        

    </ul>

    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M9.568 3H5.25A2.25 2.25 0 0 0 3 5.25v4.318c0 .597.237 1.17.659 1.591l9.581 9.581c.699.699 1.78.872 2.607.33a18.095 18.095 0 0 0 5.223-5.223c.542-.827.369-1.908-.33-2.607L11.16 3.66A2.25 2.25 0 0 0 9.568 3Z" />
            <path stroke-linecap="round" stroke-linejoin="round" d="M6 6h.008v.008H6V6Z" />
        </svg>
        Top Tags
    </div>
    <div class="flex flex-wrap gap-2 text-lg leading-8 pt-3 pl-1">
        
        
        
        
        <a href="/tags/reinforcement-learning/"><span
                class="inline-block p-0 bg-gray-800 hover:bg-gray-900 border border-gray-800 text-gray-500 hover:text-gray-300 font-light mb-1 px-5 rounded-full hover:scale-105">Reinforcement Learning&nbsp;&nbsp;2</span></a>
        
        
        
        <a href="/tags/supply-chain/"><span
                class="inline-block p-0 bg-gray-800 hover:bg-gray-900 border border-gray-800 text-gray-500 hover:text-gray-300 font-light mb-1 px-5 rounded-full hover:scale-105">Supply Chain&nbsp;&nbsp;1</span></a>
        
        
        
        <a href="/tags/minecraft/"><span
                class="inline-block p-0 bg-gray-800 hover:bg-gray-900 border border-gray-800 text-gray-500 hover:text-gray-300 font-light mb-1 px-5 rounded-full hover:scale-105">Minecraft&nbsp;&nbsp;1</span></a>
        
        
        
        <a href="/tags/nlp/"><span
                class="inline-block p-0 bg-gray-800 hover:bg-gray-900 border border-gray-800 text-gray-500 hover:text-gray-300 font-light mb-1 px-5 rounded-full hover:scale-105">NLP&nbsp;&nbsp;1</span></a>
        
        
        
        
    </div>

   
    
    <div class="aside-section-title">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6">
            <path stroke-linecap="round" stroke-linejoin="round"
                d="M21.75 6.75v10.5a2.25 2.25 0 0 1-2.25 2.25h-15a2.25 2.25 0 0 1-2.25-2.25V6.75m19.5 0A2.25 2.25 0 0 0 19.5 4.5h-15a2.25 2.25 0 0 0-2.25 2.25m19.5 0v.243a2.25 2.25 0 0 1-1.07 1.916l-7.5 4.615a2.25 2.25 0 0 1-2.36 0L3.32 8.91a2.25 2.25 0 0 1-1.07-1.916V6.75" />
        </svg>
        Contact
    </div>
    <div class="flex flex-row gap-2">
        Emailï¼mrugank.akarte@columbia.edu
    </div>
</aside>
        </div>

        <footer class="p-5 text-xl text-center mt-8 pt-8 pb-8 border-t border-gray-100/10">
    <div class="text-gray-500">
        
        &#xA9; 2025 by mrugankakarte All Rights Reserved.
        

        
        | <a class="hover:text-gray-100" href=" /en ">ðºð¸EN</a>
        
    </div>
</footer>

        <div class="cookie-container text-center py-12 text-2xl font-thin text-gray-500">
  
  <p>
    We use cookies on this website to give you the best experience on our
    site and show you relevant ads. To find out more, read our
    <a href="/en/privacy/" class="text-red-600">privacy policy</a> and <a href="/en/terms/" class="text-red-600">cookie
      policy</a>.
  </p>
  
  
  <button class="cookie-btn w-32 h-12 lg:h-22 mt-5 py-2 bg-red-600 text-white rounded-full hover:scale-110">
    Okay
  </button>
</div>
<script src="/js/cookie.js"></script>

    </div>
</body>

</html>